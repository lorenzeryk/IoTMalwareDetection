import gc
import time

import pandas
from sklearn import svm
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, matthews_corrcoef, f1_score, make_scorer
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import OrdinalEncoder


def run_models(file):
    data = load_data(file)
    data, labels = split_data(data)
    print(labels.value_counts())
    data_train, data_test, label_train, label_test = train_test_split(data, labels, random_state=100, test_size=0.25)
    del data
    del labels
    gc.collect()

    run_all_models(data_train, data_test, label_train, label_test)
    # run_grid_searches(data_train, label_train)

    return None


def load_data(file):
    print("Loading data")
    return pandas.read_csv(file)


def split_data(data):
    data.drop(labels="Unnamed: 0", axis=1, inplace=True)
    labels = pandas.DataFrame(data['label'])
    data.drop(labels='label', axis=1)

    enc = OrdinalEncoder()
    data = enc.fit_transform(data)

    return data, labels


def run_all_models(data_train, data_test, label_train, label_test):
    print("Naive Bayes")
    elapsed_time, y_pred = run_naive_bayes(data_train, data_test, label_train, label_test)
    print('Finished Run')
    print("Elapsed Time: " + str(elapsed_time) + " seconds")
    print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
    print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
    print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
    print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
    print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))

    print("SVM")
    elapsed_time, y_pred = run_svm(data_train, data_test, label_train, label_test)
    print('Finished Run')
    print("Elapsed Time: " + str(elapsed_time) + " seconds")
    print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
    print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
    print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
    print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
    print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))

    print("Decision Tree")
    elapsed_time, y_pred = run_decision_tree(data_train, data_test, label_train, label_test)
    print('Finished Run')
    print("Elapsed Time: " + str(elapsed_time) + " seconds")
    print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
    print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
    print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
    print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
    print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))

    print("MLP")
    elapsed_time, y_pred = run_mlp(data_train, data_test, label_train, label_test)
    print('Finished Run')
    print("Elapsed Time: " + str(elapsed_time) + " seconds")
    print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
    print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
    print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
    print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
    print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))

    print("Random Forest")
    elapsed_time, y_pred = run_random_forest(data_train, data_test, label_train, label_test)
    print('Finished Run')
    print("Elapsed Time: " + str(elapsed_time) + " seconds")
    print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
    print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
    print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
    print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
    print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))
    return None


def run_naive_bayes(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting Run')

    nb = GaussianNB(var_smoothing=1e-12).fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", nb.score(data_test, label_test))

    y_pred = nb.predict(data_test)

    return elapsed_time, y_pred


def run_svm(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = svm.LinearSVC(verbose=True, dual="auto").fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_decision_tree(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = tree.DecisionTreeClassifier(criterion="log_loss").fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_mlp(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = MLPClassifier(solver='adam', alpha=1e-5, learning_rate='constant', verbose=True).fit(data_train,
                                                                                                 label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_random_forest(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = RandomForestClassifier(verbose=True, n_jobs=1, n_estimators=10, criterion="log_loss").fit(data_train,
                                                                                                      label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_grid_searches(data_train, label_train):
    print("\nNaive Bayes")
    grid_search_naive_bayes(data_train, label_train)
    print("\nSVM")
    grid_search_svm(data_train, label_train)
    print("\nDecision Tree")
    grid_search_decision_tree(data_train, label_train)
    print("\nMLP")
    grid_search_mlp(data_train, label_train)
    print("\nRandom Forest")
    grid_search_random_forest(data_train, label_train)
    return None


def grid_search_naive_bayes(data_train, label_train):
    tuned_parameters = [
        {"var_smoothing": [1e-3, 1e-6, 1e-9, 1e-12, 1e-15]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(GaussianNB(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_svm(data_train, label_train):
    tuned_parameters = [
        {"penalty": ['l2'], "loss": ['hinge', 'squared_hinge'], "dual": ["auto"], 'C': [1, 10, 100, 1000]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(svm.LinearSVC(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_decision_tree(data_train, label_train):
    tuned_parameters = [
        {"criterion": ["gini", "entropy", "log_loss"], "max_features": ["sqrt", "log2"]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_mlp(data_train, label_train):
    tuned_parameters = [
        {"activation": ["relu"], "hidden_layer_sizes": [(100,), (150,), (200,), (300,), (400,), (500,)],
         "solver": ["adam"], "max_iter": [200], "alpha": [1e-9, 1e-12]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(MLPClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_random_forest(data_train, label_train):
    tuned_parameters = [
        {"n_estimators": [10, 100, 1000], "criterion": ["gini", "entropy", "log_loss"],
         "max_features": ["sqrt", "log2"], "n_jobs": [1]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(RandomForestClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)
