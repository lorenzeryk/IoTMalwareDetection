import gc

import keras.callbacks
import tensorflow as tf
from keras.metrics import F1Score
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from keras.callbacks import EarlyStopping
import keras_tuner as kt
import pandas
import time
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder

threshold = 0.5
checkpoint_path = "models/3000000.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)


def run_cnn(file):
    data = load_data(file)
    data, labels = split_data(data)
    # print(labels.value_counts())
    data_train, data_test, label_train, label_test = train_test_split(data, labels, random_state=100, test_size=0.25)
    del data
    del labels
    gc.collect()

    run_model(data_train, data_test, label_train, label_test)
    # tune_model(data_train, data_test, label_train, label_test)
    return None


def run_model(data_train, data_test, label_train, label_test):
    print("Running Model")
    metrics = [F1Score(average='micro', name='micro_f1'), F1Score(average='macro', name='macro_f1')
        , F1Score(average='weighted', name='weighted_f1'), mcc_metric, 'accuracy']

    model = Sequential()

    model.add(Dense(1500, activation='relu', input_dim=17))
    model.add(Dense(1000, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(500, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(400, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(250, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(7, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)

    start = time.time()
    print('Starting run')
    stop_early = EarlyStopping(monitor='loss', patience=5)
    checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)
    model.fit(data_train, label_train, epochs=10, batch_size=256, verbose=1, callbacks=[stop_early, checkpoint_callback])
    elapsed_time = time.time() - start
    print(elapsed_time)

    model.evaluate(data_test, label_test)


def tune_model(data_train, data_test, label_train, label_test):
    tuner = kt.Hyperband(model_builder, objective=kt.Objective("macro_f1", direction="max"), max_epochs=10, factor=3,
                         directory='IoT23', project_name='dataset_1000_0')
    stop_early = EarlyStopping(monitor='val_loss', patience=5)
    tuner.search(data_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])

    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

    print(best_hps.values)

    return None


def load_data(file):
    print("Loading data")
    return pandas.read_csv(file)


def split_data(data):
    X = pandas.DataFrame()
    used_labels = [
        "ts",
        "uid",
        "id.orig_h"
        "id.orig_p"
        "id.resp_h",
        "id.resp_p",
        "proto",
        "service",
        "duration",
        "orig_bytes",
        "resp_bytes",
        "conn_state",
        "local_orig",
        "local_resp",
        "missed_bytes",
        "history",
        "orig_pkts",
        "orig_ip_bytes",
        "resp_pkts",
        "resp_ip_bytes",
    ]
    for col in data.columns:
        if col in used_labels:
            X[col] = data[col]

    enc = OrdinalEncoder()
    X = enc.fit_transform(X)
    # Y = pandas.DataFrame(data['label'])
    Y = pandas.get_dummies(data['label']).values
    Y = enc.fit_transform(Y)
    return X, Y


def model_builder(hp):
    metrics = [F1Score(average='micro', name='micro_f1'), F1Score(average='macro', name='macro_f1')
        , F1Score(average='weighted', name='weighted_f1'), "accuracy"]

    model = Sequential()

    layer_1_units = hp.Int('first_layer', min_value=1500, max_value=2000, step=500)
    layer_2_units = hp.Int('second_layer', min_value=1000, max_value=1500, step=500)
    layer_3_units = hp.Int('third_layer', min_value=500, max_value=1000, step=500)
    layer_4_units = hp.Int('fourth_layer', min_value=300, max_value=400, step=100)
    layer_5_units = hp.Int('fifth_layer', min_value=200, max_value=250, step=50)

    model.add(Dense(layer_1_units, activation='relu', input_dim=17))
    model.add(Dense(layer_2_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_3_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_4_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_5_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(7, activation='softmax'))

    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2])

    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=hp_learning_rate), metrics=metrics)

    return model


def mcc_metric(y_true, y_pred):
  predicted = tf.cast(tf.greater(y_pred, threshold), tf.float32)
  true_pos = tf.math.count_nonzero(predicted * y_true)
  true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))
  false_pos = tf.math.count_nonzero(predicted * (y_true - 1))
  false_neg = tf.math.count_nonzero((predicted - 1) * y_true)
  x = tf.cast((true_pos + false_pos) * (true_pos + false_neg)
      * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)
  return tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / tf.sqrt(x)
