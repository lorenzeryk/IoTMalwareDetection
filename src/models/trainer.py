import os
import time

import keras.callbacks
import pandas
import tensorflow as tf
from keras.callbacks import EarlyStopping
from keras.layers import Dense, Dropout
from keras.metrics import F1Score
from keras.models import Sequential
from sklearn import svm
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, matthews_corrcoef, f1_score
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

from src.utils.enums import ModelTypes

threshold = 0.5
checkpoint_path = "models/3000000.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)

def run_all_models(data_train, data_test, label_train, label_test, models):
    for model in models:
        print("\n" + model.value)

        match model:
            case ModelTypes.NB:
                elapsed_time, y_pred = run_naive_bayes(data_train, data_test, label_train, label_test)
            case ModelTypes.SVM:
                elapsed_time, y_pred = run_svm(data_train, data_test, label_train, label_test)
            case ModelTypes.DT:
                elapsed_time, y_pred = run_decision_tree(data_train, data_test, label_train, label_test)
            case ModelTypes.MLP:
                elapsed_time, y_pred = run_mlp(data_train, data_test, label_train, label_test)
            case ModelTypes.RF:
                elapsed_time, y_pred = run_random_forest(data_train, data_test, label_train, label_test)
            case ModelTypes.CNN:
                run_cnn(data_train, data_test, label_train, label_test)

        if model is not ModelTypes.CNN:
            print('Finished Run')
            print("Elapsed Time: " + str(elapsed_time) + " seconds")
            print("Classification Report:\n", classification_report(label_test, y_pred, zero_division=0.0, digits=6))
            print("MCC Score: ", matthews_corrcoef(label_test, y_pred))
            print("Weighted F1 Score: ", f1_score(label_test, y_pred, average='weighted'))
            print("Macro F1 Score: ", f1_score(label_test, y_pred, average='macro'))
            print("Micro F1 Score: ", f1_score(label_test, y_pred, average='micro'))

    return None


def run_naive_bayes(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting Run')

    nb = GaussianNB(var_smoothing=1e-15).fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", nb.score(data_test, label_test))

    y_pred = nb.predict(data_test)

    return elapsed_time, y_pred


def run_svm(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = svm.LinearSVC(dual="auto").fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_decision_tree(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = tree.DecisionTreeClassifier(criterion="entropy", max_features="sqrt").fit(data_train, label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_mlp(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = MLPClassifier(activation='relu', alpha=1e-12, max_iter=200, hidden_layer_sizes=(200,), solver='adam').fit(data_train,
                                                                                                 label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_random_forest(data_train, data_test, label_train, label_test):
    start = time.time()
    print('Starting run')

    model = RandomForestClassifier(n_jobs=1, n_estimators=100, criterion="gini", max_features="log2").fit(data_train,
                                                                                                      label_train)
    elapsed_time = time.time() - start
    print("Score: ", model.score(data_test, label_test))

    y_pred = model.predict(data_test)

    return elapsed_time, y_pred


def run_cnn(data_train, data_test, label_train, label_test):
    label_train = tf.cast(pandas.get_dummies(label_train).values, tf.float32)
    label_test = tf.cast(pandas.get_dummies(label_test).values, tf.float32)
    print("Running Model")
    metrics = [F1Score(average='micro', name='micro_f1'), F1Score(average='macro', name='macro_f1')
        , F1Score(average='weighted', name='weighted_f1'), mcc_metric, 'accuracy']

    model = Sequential()

    model.add(Dense(1500, activation='relu', input_dim=20))
    model.add(Dense(1000, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(500, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(400, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(250, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(7, activation='softmax'))
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)

    start = time.time()
    print('Starting run')
    stop_early = EarlyStopping(monitor='loss', patience=5)
    checkpoint_callback = keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=False, verbose=1)
    model.fit(data_train, label_train, epochs=10, batch_size=256, verbose=1, callbacks=[stop_early, checkpoint_callback])
    elapsed_time = time.time() - start
    print(elapsed_time)

    model.evaluate(data_test, label_test)


def mcc_metric(y_true, y_pred):
  predicted = tf.cast(tf.greater(y_pred, threshold), tf.float32)
  true_pos = tf.math.count_nonzero(predicted * y_true)
  true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))
  false_pos = tf.math.count_nonzero(predicted * (y_true - 1))
  false_neg = tf.math.count_nonzero((predicted - 1) * y_true)
  x = tf.cast((true_pos + false_pos) * (true_pos + false_neg)
      * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)
  return tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / tf.sqrt(x)