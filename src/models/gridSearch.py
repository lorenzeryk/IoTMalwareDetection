from sklearn import svm
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import matthews_corrcoef, make_scorer
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier


def run_grid_searches(data_train, label_train):
    print("\nNaive Bayes")
    grid_search_naive_bayes(data_train, label_train)
    print("\nSVM")
    grid_search_svm(data_train, label_train)
    print("\nDecision Tree")
    grid_search_decision_tree(data_train, label_train)
    print("\nMLP")
    grid_search_mlp(data_train, label_train)
    print("\nRandom Forest")
    grid_search_random_forest(data_train, label_train)
    return None


def grid_search_naive_bayes(data_train, label_train):
    tuned_parameters = [
        {"var_smoothing": [1e-3, 1e-6, 1e-9, 1e-12, 1e-15]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(GaussianNB(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_svm(data_train, label_train):
    tuned_parameters = [
        {"penalty": ['l2'], "loss": ['hinge', 'squared_hinge'], "dual": ["auto"], 'C': [1, 10, 100, 1000]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(svm.LinearSVC(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_decision_tree(data_train, label_train):
    tuned_parameters = [
        {"criterion": ["gini", "entropy", "log_loss"], "max_features": ["sqrt", "log2"]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_mlp(data_train, label_train):
    tuned_parameters = [
        {"activation": ["relu"], "hidden_layer_sizes": [(100,), (150,), (200,), (300,), (400,), (500,)],
         "solver": ["adam"], "max_iter": [200], "alpha": [1e-9, 1e-12]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(MLPClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_random_forest(data_train, label_train):
    tuned_parameters = [
        {"n_estimators": [10, 100, 1000], "criterion": ["gini", "entropy", "log_loss"],
         "max_features": ["sqrt", "log2"], "n_jobs": [1]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(RandomForestClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=1, return_train_score=True, refit='mcc', cv=2)
    label_train = label_train.stack().values
    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)