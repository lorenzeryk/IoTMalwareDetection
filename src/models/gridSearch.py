import os

import keras_tuner as kt
import pandas
import tensorflow as tf
from keras.callbacks import EarlyStopping
from keras.layers import Dense, Dropout
from keras.metrics import F1Score
from keras.models import Sequential
from keras.optimizers import Adam
from sklearn import svm
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import matthews_corrcoef, make_scorer
from sklearn.model_selection import GridSearchCV
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier

from src.utils.enums import ModelTypes

threshold = 0.5
checkpoint_path = "models/3000000.ckpt"
checkpoint_dir = os.path.dirname(checkpoint_path)


def run_grid_searches(data_train, label_train, models):
    for model in models:
        print("\n" + model.value)

        match model:
            case ModelTypes.NB:
                grid_search_naive_bayes(data_train, label_train)
            case ModelTypes.SVM:
                grid_search_svm(data_train, label_train)
            case ModelTypes.DT:
                grid_search_decision_tree(data_train, label_train)
            case ModelTypes.MLP:
                grid_search_mlp(data_train, label_train)
            case ModelTypes.RF:
                grid_search_random_forest(data_train, label_train)
            case ModelTypes.CNN:
                tune_cnn(data_train, label_train)

    return None


def grid_search_naive_bayes(data_train, label_train):
    tuned_parameters = [
        {"var_smoothing": [1e-3, 1e-6, 1e-9, 1e-12, 1e-15]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(GaussianNB(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=0, return_train_score=True, refit='mcc', cv=2)

    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_svm(data_train, label_train):
    tuned_parameters = [
        {"penalty": ['l2'], "loss": ['hinge', 'squared_hinge'], "dual": ["auto"], 'C': [1, 10, 100, 1000]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(svm.LinearSVC(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=0, return_train_score=True, refit='mcc', cv=2)

    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_decision_tree(data_train, label_train):
    tuned_parameters = [
        {"criterion": ["gini", "entropy", "log_loss"], "max_features": ["sqrt", "log2"]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=0, return_train_score=True, refit='mcc', cv=2)

    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_mlp(data_train, label_train):
    tuned_parameters = [
        {"activation": ["relu"], "hidden_layer_sizes": [(100,), (150,), (200,), (300,), (400,), (500,)],
         "solver": ["adam"], "max_iter": [200], "alpha": [1e-9, 1e-12]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(MLPClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6, pre_dispatch='n_jobs',
                      verbose=0, return_train_score=True, refit='mcc', cv=2)

    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def grid_search_random_forest(data_train, label_train):
    tuned_parameters = [
        {"n_estimators": [10, 100, 1000], "criterion": ["gini", "entropy", "log_loss"],
         "max_features": ["sqrt", "log2"], "n_jobs": [1]}
    ]

    scores = {'mcc': make_scorer(matthews_corrcoef), 'f1': 'f1_macro'}

    gs = GridSearchCV(RandomForestClassifier(), param_grid=tuned_parameters, scoring=scores, n_jobs=6,
                      pre_dispatch='n_jobs', verbose=0, return_train_score=True, refit='mcc', cv=2)

    gs.fit(data_train, label_train)
    print(gs.best_params_)
    print(gs.best_score_)
    print(gs.refit_time_)


def tune_cnn(data_train, label_train):
    label_train = tf.cast(pandas.get_dummies(label_train).values, tf.float32)
    tuner = kt.Hyperband(model_builder, objective=kt.Objective("macro_f1", direction="max"), max_epochs=10, factor=3,
                         directory='IoT23', project_name='dataset_1000_0')
    stop_early = EarlyStopping(monitor='val_loss', patience=5)
    tuner.search(data_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])

    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

    print(best_hps.values)

    return None


def model_builder(hp):
    metrics = [F1Score(average='micro', name='micro_f1'), F1Score(average='macro', name='macro_f1')
        , F1Score(average='weighted', name='weighted_f1'), "accuracy"]

    model = Sequential()

    layer_1_units = hp.Int('first_layer', min_value=1500, max_value=2000, step=500)
    layer_2_units = hp.Int('second_layer', min_value=1000, max_value=1500, step=500)
    layer_3_units = hp.Int('third_layer', min_value=500, max_value=1000, step=500)
    layer_4_units = hp.Int('fourth_layer', min_value=300, max_value=400, step=100)
    layer_5_units = hp.Int('fifth_layer', min_value=200, max_value=250, step=50)

    model.add(Dense(layer_1_units, activation='relu', input_dim=20))
    model.add(Dense(layer_2_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_3_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_4_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(layer_5_units, activation='relu'))
    model.add(Dropout(0.2))
    model.add(Dense(7, activation='softmax'))

    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2])

    model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=hp_learning_rate), metrics=metrics)

    return model


def mcc_metric(y_true, y_pred):
  predicted = tf.cast(tf.greater(y_pred, threshold), tf.float32)
  true_pos = tf.math.count_nonzero(predicted * y_true)
  true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))
  false_pos = tf.math.count_nonzero(predicted * (y_true - 1))
  false_neg = tf.math.count_nonzero((predicted - 1) * y_true)
  x = tf.cast((true_pos + false_pos) * (true_pos + false_neg)
      * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)
  return tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / tf.sqrt(x)
